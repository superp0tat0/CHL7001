{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gX5AKgQ3pEfD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "5mDBQ17tpHtj",
    "outputId": "fc8abe96-c5ae-427f-b654-8324c39b4f4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>study_label</th>\n",
       "      <th>image_label</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2.jpg</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>typical</td>\n",
       "      <td>opacity</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>negative</td>\n",
       "      <td>none</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc.jpg</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>typical</td>\n",
       "      <td>opacity</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                              boxes  \\\n",
       "0  000a312787f2.jpg  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f.jpg                                                NaN   \n",
       "2  0012ff7358bc.jpg  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "\n",
       "  study_label image_label  dim0  dim1  split  \n",
       "0     typical     opacity  3488  4256  train  \n",
       "1    negative        none  2320  2832  train  \n",
       "2     typical     opacity  2544  3056  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Preparation\n",
    "\n",
    "df_image = pd.read_csv('./image_info/train_image_level.csv')\n",
    "df_study = pd.read_csv('./image_info/train_study_level.csv')\n",
    "df_study['id'] = df_study['id'].str.replace('_study',\"\")\n",
    "df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)\n",
    "df_train = df_image.merge(df_study, on='StudyInstanceUID')\n",
    "df_train.loc[df_train['Negative for Pneumonia']==1, 'study_label'] = 'negative'\n",
    "df_train.loc[df_train['Typical Appearance']==1, 'study_label'] = 'typical'\n",
    "df_train.loc[df_train['Indeterminate Appearance']==1, 'study_label'] = 'indeterminate'\n",
    "df_train.loc[df_train['Atypical Appearance']==1, 'study_label'] = 'atypical'\n",
    "df_train.drop(['Negative for Pneumonia','Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'], axis=1, inplace=True)\n",
    "df_train['id'] = df_train['id'].str.replace('_image', '.jpg')\n",
    "df_train['image_label'] = df_train['label'].str.split().apply(lambda x : x[0])\n",
    "df_size = pd.read_csv('./image_info/size.csv')\n",
    "df_train = df_train.merge(df_size, on='id')\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# Get the data generator for different image preprocessing technics\n",
    "def preprocess_image(img):\n",
    "    equ_img = exposure.equalize_adapthist(img/255, clip_limit=0.05, kernel_size=24)\n",
    "    return equ_img\n",
    "\n",
    "def get_data_generators(name, CLAHE = False):\n",
    "    \n",
    "    image_generator = ImageDataGenerator(\n",
    "        validation_split=0.2,\n",
    "        horizontal_flip = True,\n",
    "        zoom_range = 0.15,\n",
    "        rotation_range = 10,\n",
    "        brightness_range = [0.8, 1.2],\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    image_generator_valid = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "    train_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe = df_train,\n",
    "            directory='./images/512' + name + '/train',\n",
    "            x_col = 'id',\n",
    "            y_col =  'study_label',  \n",
    "            target_size=(img_size, img_size),\n",
    "            batch_size=batch_size,\n",
    "            subset='training', seed = 23,\n",
    "            class_mode='categorical',\n",
    "            preprocessing_function = preprocess_image if CLAHE else None) \n",
    "\n",
    "    valid_generator=image_generator_valid.flow_from_dataframe(\n",
    "        dataframe = df_train,\n",
    "        directory='./images/512' + name + '/train',\n",
    "        x_col = 'id',\n",
    "        y_col = 'study_label',\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        subset='validation', shuffle=False, seed=23,\n",
    "        class_mode='categorical',\n",
    "        preprocessing_function = preprocess_image if CLAHE else None)\n",
    "    \n",
    "    return(train_generator, valid_generator)\n",
    "\n",
    "# Get the untrained model\n",
    "def get_model():\n",
    "    pre_model = DenseNet121(weights=None, include_top=False, input_shape=(img_size,img_size,3))\n",
    "    out = Dense(64, activation='sigmoid')(pre_model.output)\n",
    "    pre_model = Model(inputs=pre_model.input, outputs=out)\n",
    "    x = pre_model.layers[-2].output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "    model = Model(pre_model.input, output)\n",
    "    return(model)\n",
    "\n",
    "# Report the accuracy and other metrics\n",
    "def validate_model(model, valid_generator):\n",
    "    predictions = model.predict_generator(valid_generator, 80)\n",
    "    truth = valid_generator.classes\n",
    "    result = np.argmax(predictions, axis = 1)\n",
    "    print(classification_report(truth, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6MVAO-eLpWOw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5068 validated image filenames belonging to 4 classes.\n",
      "Found 1266 validated image filenames belonging to 4 classes.\n",
      "80/80 [==============================] - 1843s 23s/step - loss: 1.2868 - accuracy: 0.4637 - val_loss: 58555.6094 - val_accuracy: 0.4597\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 80 batches). You may need to use the repeat() function when building your dataset.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.00      0.00      0.00       239\n",
      "           2       0.00      0.00      0.00       356\n",
      "           3       0.46      1.00      0.63       582\n",
      "\n",
      "    accuracy                           0.46      1266\n",
      "   macro avg       0.11      0.25      0.16      1266\n",
      "weighted avg       0.21      0.46      0.29      1266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Images Training without Image Enhancements\n",
    "\n",
    "model = get_model()\n",
    "train_generator, valid_generator = get_data_generators(\"jpg\")\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=1,\n",
    "      validation_data=valid_generator,\n",
    "      verbose=1)\n",
    "\n",
    "validate_model(model, valid_generator)\n",
    "model.save(\"./models/dense121_naive.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luRlqcEBqls0",
    "outputId": "4ecdd22b-9c9f-4461-a008-49823b1a0170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5068 validated image filenames belonging to 4 classes.\n",
      "Found 1266 validated image filenames belonging to 4 classes.\n",
      "80/80 [==============================] - 1494s 18s/step - loss: 1.2912 - accuracy: 0.4655 - val_loss: 2636.4927 - val_accuracy: 0.4597\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 80 batches). You may need to use the repeat() function when building your dataset.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.00      0.00      0.00       239\n",
      "           2       0.00      0.00      0.00       356\n",
      "           3       0.46      1.00      0.63       582\n",
      "\n",
      "    accuracy                           0.46      1266\n",
      "   macro avg       0.11      0.25      0.16      1266\n",
      "weighted avg       0.21      0.46      0.29      1266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Images Training with High-frequency emphasis filtering\n",
    "\n",
    "model = get_model()\n",
    "train_generator, valid_generator = get_data_generators(\"hef\")\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=1,\n",
    "      validation_data=valid_generator,\n",
    "      verbose=1)\n",
    "\n",
    "validate_model(model, valid_generator)\n",
    "model.save(\"./models/dense121_hef.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5068 validated image filenames belonging to 4 classes.\n",
      "Found 1266 validated image filenames belonging to 4 classes.\n",
      "80/80 [==============================] - 1649s 20s/step - loss: 1.3268 - accuracy: 0.4586 - val_loss: 2894.1199 - val_accuracy: 0.2820\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 80 batches). You may need to use the repeat() function when building your dataset.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.25      0.00      0.01       239\n",
      "           2       0.28      1.00      0.44       356\n",
      "           3       0.00      0.00      0.00       582\n",
      "\n",
      "    accuracy                           0.28      1266\n",
      "   macro avg       0.13      0.25      0.11      1266\n",
      "weighted avg       0.13      0.28      0.13      1266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Images Training with Unsharp Masking\n",
    "\n",
    "model = get_model()\n",
    "train_generator, valid_generator = get_data_generators(\"um\")\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=1,\n",
    "      validation_data=valid_generator,\n",
    "      verbose=1)\n",
    "\n",
    "validate_model(model, valid_generator)\n",
    "model.save(\"./models/dense121_um.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5068 validated image filenames belonging to 4 classes.\n",
      "Found 1266 validated image filenames belonging to 4 classes.\n",
      "80/80 [==============================] - 1703s 21s/step - loss: 1.2902 - accuracy: 0.4542 - val_loss: 23678.5234 - val_accuracy: 0.4589\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 80 batches). You may need to use the repeat() function when building your dataset.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        89\n",
      "           1       0.00      0.00      0.00       239\n",
      "           2       0.00      0.00      0.00       356\n",
      "           3       0.46      1.00      0.63       582\n",
      "\n",
      "    accuracy                           0.46      1266\n",
      "   macro avg       0.11      0.25      0.16      1266\n",
      "weighted avg       0.21      0.46      0.29      1266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Images Trainning with Contrast Limited Adaptive Histogram Equalization\n",
    "\n",
    "model = get_model()\n",
    "train_generator, valid_generator = get_data_generators(\"jpg\", CLAHE = True)\n",
    "model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=1,\n",
    "      validation_data=valid_generator,\n",
    "      verbose=1)\n",
    "\n",
    "validate_model(model, valid_generator)\n",
    "model.save(\"./models/dense121_clahe.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xray_PreData_Compare.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
